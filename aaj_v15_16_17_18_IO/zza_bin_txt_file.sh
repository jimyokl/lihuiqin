
大多数C项目中，很少需要判断文件是文本还是二进制:
    文件的读写通常是“已知其格式”的场景；
    如果要处理不同类型的文件（如做编辑器、格式转换器、自动识别工具），那才可能需要判断

C并不定义“文本文件”和“二进制文件”的内部结构区别，只通过打开文件的方式（r/rb）来决定是否处理换行符等转换。
    文本文件	 "r"、"w"、"a"      读写按文本处理，可能转换换行符
    二进制文件	"rb"、"wb"、"ab"	不进行任何换行符处理，原样读写

为什么有这个区别？
    在 Windows 系统中：文本模式读取时，"\r\n" 会自动转换成 "\n"；
    写入时，写 "\n" 会自动转成 "\r\n"；
    如果你读写二进制文件（如图片、音频、可执行文件）却用文本模式，就可能破坏文件内容。

    在 Linux/Unix/macOS 系统中：
    文本模式和二进制模式几乎一样，但出于可移植性考虑，写二进制文件一定要用 "b" 模式。


检查是否存在控制字符（如、 除了 `\n` 和 `\t`）
判断文件是文本还是二进制，检测文件开始几个字符是否可打印
while ((c = fgetc(file)) != EOF && count < 1024) 
{
    // 如果发现不可打印字符（除了常见的换行、回车、制表符），认为是二进制文件
    if ((c != '\n' && c != '\r' && c != '\t') && (c < 32 || c > 126)) 
    {
        fclose(file);  return 1; // 是二进制文件
    }
    count++;
}
// `\0`是c<32，
// `\x01` \~ `\x1F`常用于用于控制设备（如终端、打印机等）行为，但是也在很少很少的情况下用于文本文件
// c>126: 

不可打印字符检测法”是否常用？
    虽然不是 C 标准库支持，但在以下场景下，它是比较常用的“启发式”判断方法：

    1. 跨平台工具：比如 Git 就用类似的方法判断是文本文件还是二进制，以决定是否需要做换行符转换。
    2. 文件识别工具：像 Unix/Linux 中的 file 命令就是基于魔数 + 不可打印字符等多重启发式检测的。
    3. 自写脚本工具/编辑器插件：想自动区分文件类型时，这种检测方式简单有效。


魔数？
    这个术语来自早期程序员的幽默，因为这些字节序列在文件开始处
    魔数--Magic Number，是文件头部（通常是前几个字节）的一组特定字节序列，用于标识文件的类型。


EOF：
    OS文件系统不会在文件结尾加一个“EOF”标志，文件的长度（以字节计）是文件结束的唯一标志。

    当程序读取文件时，OS通过返回“读取0个字节”或特殊返回值，告诉程序已经读到结尾。
    C语言EOF是一个宏，值为-1，EOF是程序运行时的一个状态码，不是文件中实际存在的字节。

二进制文件中换行符、\0空字符：
    bin文件中少有换行符, 它们不以“行”的概念来组织内容。
    虽然可能包含某些字节的值正好是\r（13）或\n（10），但只是数据的一部分，不是为了格式化可读文本。


关于`\0`（空字符, `\x00`, null character）：
    在文本数据中，`\0` 不应该自然出现；
    但在读取二进制文件或含有非文本内容（如嵌入的 `\0` 字节）的数据时，
    fgets会在读取到`\0`后就认为是字符串终止，虽然它会继续读入剩余字符，但程序在处理这些数据时会被误导，
    以为字符串到此为止。

    在文本文件或字符串中看到 `\0`，很可能表示：编码问题、数据损坏或不当的数据读取操作，错误地将二进制数据当作文本处理。

    大多数情况下，字符串中的'\0'不会被写入文件，除非你显式指定要写入它（手动控制长度）
        fputs和fprintf（带%s）都会在遇到'\0'时停止处理字符串，'\0'不会写入文件。
        fwrite是按字节写入的，不依赖'\0'来判断结尾，
        fprintf(fp, "%s", str);
        fwrite(str, sizeof(char), sizeof(str), fp);